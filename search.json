[
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Code of conduct: Creating a friendly and intellectually stimulating space",
    "section": "",
    "text": "Version 1.0, 2023-08-04 (This CoC is based on the CoC of the German Reproducibility Network, Version 1.0, from 2022-11-09)\nEpistemic responsibility1 ‚Äì which is based on virtues such as open-mindedness, diligence, and honesty ‚Äì and interpersonal respect are central values of this project. Therefore we aim to create an open, friendly, diverse, inclusive, and welcoming community and scholarly context in which insights and criticisms are welcome from all participants, regardless of personal characteristics or academic rank.\n\n\n\nEpistemic responsibility and trustworthiness are core values for us as scientists. Critical discussion and evaluation of research has a vital function for the self-correction and progress of science, and we gracefully accept constructive criticism. When criticizing others‚Äô research, we differentiate between the research (as output) and the researcher as a person. We acknowledge that such a separation is sometimes difficult. We are aware of the impact that criticism can have on the lives and careers of researchers, in particular early career researchers, and always aim to balance the values of intellectual honesty and kindness towards our colleagues.\nWe are convinced that a diversity of personal backgrounds and viewpoints is key to scientific progress. We embrace this diversity and believe in the power of collaboration and co-creation. We include as many people as possible in group interactions by being respectful and inviting.\nWe discuss views and claims based on the evidence and the quality of arguments, not based on the status of the people making the claim, nor their personal characteristics or their academic rank.\nScientific debates can feel challenging or even uncomfortable. But also in heated debates we show respect and civility to our fellow colleagues, without discrimination or personal attacks.\nWe respect the private sphere of other people. We never share others‚Äô private information without their consent.\n\n\n\n\n‚Ä¶ any form of public or private harassment, either in person, on event platforms or social media. This includes abusive, discriminatory, derogatory, or demeaning language and behaviour. Sexual language and imagery is not appropriate for any event venue or talks. Participants violating these rules may be sanctioned or expelled from the project.\n\n\n\nProject maintainers are responsible for clarifying and enforcing the standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all project spaces, and also applies when an individual is officially representing the project in public spaces. Examples of representing our project include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nIf you think that a project member acts against these guidelines, please report this to one of the project maintainers. The complaint will be investigated based on the principles of impartiality, proportionality, and due process ensuring the anonymity of both reporter and reportee. We ask all involved parties to await the outcome of such investigations before they publicly comment or act on potentially unfounded allegations. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project‚Äôs leadership.\n\n\n\nEcheverri, S. (2011). Epistemic Responsibility and Perceptual Experience. In D. Lauer, C. Laudou, R. Celikates, & G. W. Bertram (Hrsg.), Exp√©rience Et R√©flexivit√©: Perspectives au-Del√† de L‚ÄôEmpirisme Et de L‚ÄôId√©alisme. L‚Äôharmattan.\nLechner, I. M., Mokkink, L., de Ridder, J., van Woudenberg, R., Bouter, L., & Tijdink, J. K. (2022). The core epistemic responsibilities of universities: Results from a Delphi study Preprint. Open Science Framework.\n\n\n\n\nCoC of the German Reproducibility Network\nFriendly Space Policy of the Barcamp Open Science\nThe TU Eindhoven Code of Scientific Conduct\nThe IGDORE CoC\nSimine Vazire‚Äôs ‚ÄûOath for Scientists‚Äô\nPeels, R., van Woudenberg, R., de Ridder, J., & Bouter, L. (2020). Academia‚Äôs Big Five: A normative taxonomy for the epistemic responsibilities of universities [version 2; peer review: 2 approved]. F1000Research, 8(862). https://doi.org/10.12688/f1000research.19459.2\nThe Contributor Covenant, version 2.1"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#this-coc-is-inspired-by",
    "href": "CODE_OF_CONDUCT.html#this-coc-is-inspired-by",
    "title": "Code of conduct: Creating a friendly and intellectually stimulating space",
    "section": "",
    "text": "CoC of the German Reproducibility Network\nFriendly Space Policy of the Barcamp Open Science\nThe TU Eindhoven Code of Scientific Conduct\nThe IGDORE CoC\nSimine Vazire‚Äôs ‚ÄûOath for Scientists‚Äô\nPeels, R., van Woudenberg, R., de Ridder, J., & Bouter, L. (2020). Academia‚Äôs Big Five: A normative taxonomy for the epistemic responsibilities of universities [version 2; peer review: 2 approved]. F1000Research, 8(862). https://doi.org/10.12688/f1000research.19459.2\nThe Contributor Covenant, version 2.1"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#footnotes",
    "href": "CODE_OF_CONDUCT.html#footnotes",
    "title": "Code of conduct: Creating a friendly and intellectually stimulating space",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEpistemic Responsibility is about the goal to ‚Äòproduce, maintain, and disseminate knowledge and other knowledge-related (or: epistemic) goods, such as insight, rational belief, and understanding‚Äô (Lechner et al, 2022) and has been defined as ‚Äúrelated to the capacity to engage in adequate policies in the search of truth, the ability to give reasons, or the readiness to revise one‚Äôs beliefs in the light of new evidence.‚Äô (Echeverri, 2011).‚Ü©Ô∏é"
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "üë• Team / Contribute",
    "section": "",
    "text": "The RESQUE framework is a collaborative project initiated by the German Psychological Society (DGPs).\nThis project is a community effort with many contributors:\n‚Ä¶ all who wrote comments with many constructive suggestions ‚Ä¶ and many more who gave extended feedback on the proposal! üôè"
  },
  {
    "objectID": "team.html#how-to-contribute",
    "href": "team.html#how-to-contribute",
    "title": "üë• Team / Contribute",
    "section": "How to contribute",
    "text": "How to contribute\nJoin our mailing list to receive news and updates about the RESQUE framework.\nFor minor updates and minor feature requests, please use the Discussions of the Github repository.\nIf you want to collaborate scientifically on the project, please contact one of the project maintainers (Felix Sch√∂nbrodt; Anne G√§rtner; Daniel Leising).\nIf you want to develop an expansion pack for your field, please contact Anne G√§rtner.\nPlease note and respect our Code of Conduct."
  },
  {
    "objectID": "team.html#partners-and-supporters-of-resque",
    "href": "team.html#partners-and-supporters-of-resque",
    "title": "üë• Team / Contribute",
    "section": "Partners and supporters of RESQUE",
    "text": "Partners and supporters of RESQUE"
  },
  {
    "objectID": "publications/Presentations.html",
    "href": "publications/Presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "To get an overview about the RESQUE project, you can look at our presentation slides. In general, the information on this website is more up to date than the slides.\n\nRESQUE: Overview in 8 slides\n\nSlightly longer slide decks with more information:\n\nSch√∂nbrodt (2023-03): Responsible Research Assessment: A practical recommendation for the evaluation of research quality beyond h-index and journal impact factors\nG√§rtner (2023-09): Responsible Research Assessment II: The RESQUE web form for hiring and promotion\nSlides for meetings for an Expansion Pack\nSch√∂nbrodt (2024-06): Responsible Research Assessment: A pitch for hiring committees",
    "crumbs": [
      "üìî Publications",
      "Presentations"
    ]
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "The general framework of RESQUE is described in:\n\n[1]  Sch√∂nbrodt, F. D., G√§rtner, A., Frank, M., Gollwitzer, M., Ihle, M., Mischkowski, D., Phan, L. V., Schmitt, M., Scheel, A. M., Schubert, A.-L., Steinberg, U., & Leising, D. (2022). Responsible Research Assessment I: Implementing DORA for hiring and promotion in psychology. https://doi.org/10.31234/osf.io/rgh5b\n\n\nThe specific RESQUE rating schemes are described in:\n\n[2]  G√§rtner, A., Leising, D., & Sch√∂nbrodt, F. D. (2022). Responsible Research Assessment II: A specific proposal for hiring and promotion in psychology. https://doi.org/10.31234/osf.io/5yexm\n\nand\n\n[3]  G√§rtner, A., Leising, D., & Sch√∂nbrodt, F. D. (2023). Empfehlungen zur Bewertung wissenschaftlicher Leistungen bei Berufungsverfahren in der Psychologie. Psychologische Rundschau, 74(3), 166‚Äì174. https://doi.org/10.1026/0033-3042/a000630\n\n(Note: these publications refer to version 0.1 of the RESQUE scheme; as the rating scheme will be continuously updated based on community feedback and ongoing evaluation studies, some divergences to these publications will arise).",
    "crumbs": [
      "üìî Publications",
      "Publications"
    ]
  },
  {
    "objectID": "news/2024-02-26-theory_indicators.html",
    "href": "news/2024-02-26-theory_indicators.html",
    "title": "New indicators for theory-guided research developed",
    "section": "",
    "text": "A working group consisting of Nele Freyer, Jens Lange, Daniel Leising, Philipp Musfeld, and Felix Sch√∂nbrodt developed a set of indicators that allows to evaluate theory-guided research.\nThe indicators cover both narrative and formal theories, and they cover both theory development and theory testing.\nIn the general philosophy of RESQUE, these indicators mostly focus on ‚Äúhygiene factors‚Äù: Properties of theory-guided research that are necessary but not sufficient for high-quality research.\nHere are the indicators:\n\n\n\n\nTheory usage and development\n\nIn the following, the term ‚Äòtheory‚Äô is used for a set of (interconnected) ideas that explain empirical phenomena. Theories may be expressed in a narrative and/or a more formalized manner. The term ‚Äòmodel‚Äô is reserved for a (part of a) theory that is expressed mathematically or algorithmically.\n\n\n\n\n\n[P_Theorizing] Theory-guided research and theory development\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô ]\n\n\n[DescriptiveExploratory] This research was mainly descriptive and/or exploratory, without clear reference to a theory[TheoryGuided] In this research, at least one theory was (further) developed and/or evaluated[NotApplicable] Not applicable / cannot answer the question\n\n\n\n\n\n[P_Theorizing_NAExplanation] ‚§∑ Not Applicable: Explanation\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòNotApplicable‚Äô ]\n\n\n\n\n\n\n[P_Theorizing_Quality] The paper ‚Ä¶\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô ]\n\n\n[P_Theorizing_Quality_NarrativeAccount] contains an explicit narrative account of the phenomena that are to be explained, and of one or more hypothetical mechanisms accounting for them (i.e., a theory).[P_Theorizing_Quality_NarrativeDefinitions] contains explicit narrative definitions of each element (concepts, relationships, etc.) in the theory. All of this is made easily findable (e.g., under a standard heading ‚ÄòDefinitions‚Äô).[P_Theorizing_Quality_FormalizedAccount] contains a formalized account of the theory (i.e., a model) using a commonly accepted standard notation (e.g., mathematical or logical operations, ODD protocol for ABMs). This includes all connections among the elements of the theory, and a formalization of the phenomena that are to be explained.[P_Theorizing_Quality_MathProps] contains a formalized account of the theory (i.e., a model) and explicates the basic mathematical properties of all elements of the model (e.g., scalar vs.¬†matrix; dimensionality; units carrying the information).[P_Theorizing_Quality_PossibleValues] contains a formalized account of the theory (i.e., a model) and explicates the possible values for all elements of the model (i.e., upper and lower bounds, scale level).[P_Theorizing_Quality_ObjectiveDerivation] contains a formalized account of the theory (i.e., a model) and explicitly derives predictions from that. The derivation is objective, in the sense that any person would come to the exact same predictions.[P_Theorizing_Quality_Falsifiability] contains a formalized account of the theory (i.e., a model) and all stated predictions are in principle falsifiable (before considering operationalizations).\n\n\n\n\n\n[P_Theorizing_Type] In what language or system is the theory formulated?\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô ]\n\n\n[Narrative] Narrative[Mathematical] Mathematical[FormalLogic] Formal-Logic[ABM] Agent-based model[Other] Other (please specify)\n\n\n\n\n\n[P_Theory_Type_Other] Theory type/ Language: Other\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô && $P_Theorizing_Type === ‚ÄòOther‚Äô ]\n\n\n\n\n\n\n[P_Theorizing_Contribution] How much did you personally contribute to this version of the theory?\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô ]\n\n\n[No] I did not contribute to this version of the theory itself (i.e., I did no theoretical work beyond testing a theory)[Yes] I did contribute significantly to this version of the theory\n\n\n\n\n\n[P_Theorizing_ContributionType] I significantly contributed to ‚Ä¶\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô && $P_Theorizing_Contribution === ‚ÄòYes‚Äô ]\n\n\n[P_Theorizing_ContributionType_NarrativeDevelopment] the overall development of an entire narrative theory[P_Theorizing_ContributionType_NarrativeRefinement] the expansion or refinement of an existing narrative theory[P_Theorizing_ContributionType_FormalizationFirst] the first formalization of an existing narrative theory[P_Theorizing_ContributionType_FormalizationStandAlone] the overall development of an entire formal model of which there was no narrative version[P_Theorizing_ContributionType_FormalizationRefinement] the expansion or refinement of an existing formal model\n\n\n\n\n\n[P_Theorizing_Test] Did you test (a part of) this theory?\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô ]\n\n\n[No] No[Yes] Yes\n\n\n\n\n\n[P_Theorizing_Test_Quality] The paper ‚Ä¶\n\n\n[ Condition: $P_Suitable === ‚ÄòYes‚Äô && $P_Theorizing === ‚ÄòTheoryGuided‚Äô && $P_Theorizing_Test === ‚ÄòYes‚Äô ]\n\n\n[P_Theorizing_Test_Quality_Assumptions] describes all necessary assumptions that were necessary to make the theory testable (including ad-hoc assumptions).[P_Theorizing_Test_Quality_Operationalization] describes which, how, and why elements of the theory are measured, estimated, or fixed to specific values.[P_Theorizing_Test_Quality_Derivation] makes clear how the tested hypotheses logically and stringently follow from the theory.[P_Theorizing_Test_Quality_Evaluation] evaluates the relative and/or absolute model fit with appropriate procedures (e.g., out-of-sample cross-validation, AIC, BIC, LOO, Bayes Factors).[P_Theorizing_Test_Quality_Discussion] contains an explicit discussion as to what the results mean for the theory that was tested."
  },
  {
    "objectID": "news/2023-09-04-Etzel_preprint.html",
    "href": "news/2023-09-04-Etzel_preprint.html",
    "title": "Preprint published by Franka Etzel on an evaluation study",
    "section": "",
    "text": "63 papers nominated by 21 participating researchers from personality and social psychology were rated by external raters (i.e., not the authors themselves) with the RESQUE-Pubs scheme. Inter-rater reliability, associations between the new and traditional indicators, and feedback from the participants on the new tool were examined. Inter-rater reliability for the three raters varied between the different items of the scheme. Besides a negative association between the new indicators and the uncorrected h-index, no other significant associations were found. The feedback from participants revealed the importance of transparency concerning the scheme.\nThe RESQUE-Pubs scheme good be properly apply applied to 84% of all submitted papers. The average rigor score was around 35%.\n(Note that the RESQUE-Pubs scheme evolved since that study).\nYou can read the study here:\nEtzel, F. T. (2023, September 4). *One step closer towards responsible research assessment in psychology: Evaluation and testing of a new tool in practice. https://doi.org/10.31234/osf.io/3uf7w"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RESQUE: The Research Quality Evaluation scheme for psychological research",
    "section": "",
    "text": "See all news here.\n\n\n\n\n\n2024-03-21: Einstein Foundation Award \n\n\n\n2024-02-26: New indicators for theory-guided research developed \n\n\n\n2023-12-12: RESQUE website is live! \n\n\n\n2023-09-04: Preprint published by Franka Etzel on an evaluation study \n\n\n\n\nNo matching items\nThe Research Quality Evaluation (RESQUE) framework provides recommendations for a responsible research assessment that does not rely on flawed metrics such as the journal impact factor or the h-index.\nIn alignment with the principles of CoARA, this approach acknowledges diverse academic contributions, prioritizes the quality of work rather than its volume, and integrates qualitative peer assessment with the responsible use of quantitative indicators.\nPrimarily designed to assist hiring and tenure committees, it emphasizes that the indicators and algorithmic methods serve as tools to support, not replace, decision-making processes. By automating the generation of relevant candidate information, this approach enhances the effectiveness of human expertise in evaluating potential hires and tenure candidates.\nRESQUE provides objective quality and impact indicators for three types of research outputs:\nIt is primarily developed for the field of psychology, but might be easily transferred to neighbouring empirical scientific fields.\nJoin our mailing list to receive news and updates about the RESQUE framework."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "RESQUE: The Research Quality Evaluation scheme for psychological research",
    "section": "Resources",
    "text": "Resources\n\n‚òëÔ∏è Rating schemes: Core set\nWith the goal to make data entry for applicants and hiring committees as easy and frictionless as possible, we developed the RESQUE Collector app that allows to provide information for your best research outputs and to export the data in a JSON format.\nWe provide three rating schemes for ‚Ä¶\n\nPublications, preprints, book chapters, etc. (RESQUE-Pubs) - ‚úÖ v0.3, ready for use (but still likely to change)\nData sets (RESQUE-Data) - ‚ùå in development, not implemented in Collector app yet\nResearch software (RESQUE-Software) - ‚ùå in development, not implemented in Collector app yet\n\n(Note: The web form currently only implements RESQUE-Pubs)\n\n\n‚òëÔ∏é Rating schemes: Expansion packs\nWe aim to develop and collect disciplinary expansion packs (EPs) with specific indicators that are relevant for a subfield. If you plan to provide an expansion pack, please get in contact with us (we will help to implement that in the web form).\nSuch EPs ideally are contributed from a legit academic community and stem from a consensus process. Before including EPs in this project, we do a minimal review for suitability.\nThe subdivisions of the German Psychological Society have been asked to discuss the need for discipline-specific indicators.\n\n\nüìä The RESQUE Research Profile\nWe provide R scripts that ‚Ä¶\n\nload and aggregate multiple json files with RESQUE ratings\nenrich the data with other sources of information (e.g.¬†citation counts & normalized citation counts from OpenAlex, impact metrics from BIP!)\nprovide candidate profiles that can be requested by hiring and tenure committees, or used by candidates as an attachment to their CV or website.\n\nAn interactive dashboard allows to compare multiple candidates and to zoom into the profiles of specific candidates."
  },
  {
    "objectID": "index.html#partners-and-supporters-of-resque",
    "href": "index.html#partners-and-supporters-of-resque",
    "title": "RESQUE: The Research Quality Evaluation scheme for psychological research",
    "section": "Partners and supporters of RESQUE",
    "text": "Partners and supporters of RESQUE"
  },
  {
    "objectID": "for_committees.html",
    "href": "for_committees.html",
    "title": "üöÄ For hiring/tenure committees",
    "section": "",
    "text": "TODO - this is not complete.\nThe RESQUE framework decisively promotes a ‚Äúbuffett table approach‚Äù: From the list of available indicators, hiring committees choose those which show a fit to the position and to the preferences and the research culture of the institution.\nThe RESQUE App already has basic customization features. With the simple Form Builder website, committees can choose:\n\nThe maximum number of submittable research outputs (default: 10)\nThe number of top papers (‚Äòbest research outputs‚Äô) that can be selected (default: 3)\nThe threshold for ‚Äònumber of required research outputs‚Äô warning (default: 5): The app computes an average rigor score, but that needs at least some scoreable research outputs.\n\nThe app is completely open source, so all indicators can be adjusted, removed, or new indicators added. However, we are happy to assist in customizing the app for your hiring committee.\nTODO:\n\nShow recommended paragraph in job ad\ncf.¬†Lange et al.: Commit to weights and indicator sets when publishing the job ad; we recommend to publish the weights and indicators along with the ad.\nShow instructions for applicants"
  },
  {
    "objectID": "for_committees.html#as-hiring-committees",
    "href": "for_committees.html#as-hiring-committees",
    "title": "üöÄ For hiring/tenure committees",
    "section": "",
    "text": "TODO - this is not complete.\nThe RESQUE framework decisively promotes a ‚Äúbuffett table approach‚Äù: From the list of available indicators, hiring committees choose those which show a fit to the position and to the preferences and the research culture of the institution.\nThe RESQUE App already has basic customization features. With the simple Form Builder website, committees can choose:\n\nThe maximum number of submittable research outputs (default: 10)\nThe number of top papers (‚Äòbest research outputs‚Äô) that can be selected (default: 3)\nThe threshold for ‚Äònumber of required research outputs‚Äô warning (default: 5): The app computes an average rigor score, but that needs at least some scoreable research outputs.\n\nThe app is completely open source, so all indicators can be adjusted, removed, or new indicators added. However, we are happy to assist in customizing the app for your hiring committee.\nTODO:\n\nShow recommended paragraph in job ad\ncf.¬†Lange et al.: Commit to weights and indicator sets when publishing the job ad; we recommend to publish the weights and indicators along with the ad.\nShow instructions for applicants"
  },
  {
    "objectID": "for_committees.html#as-tenure-track-committees",
    "href": "for_committees.html#as-tenure-track-committees",
    "title": "üöÄ For hiring/tenure committees",
    "section": "‚Ä¶as tenure track committees",
    "text": "‚Ä¶as tenure track committees\nTODO"
  },
  {
    "objectID": "eval_projects.html",
    "href": "eval_projects.html",
    "title": "üîé Evaluation Projects",
    "section": "",
    "text": "Several research projects work(ed) on the evaluation of the RESQUE rating scheme:\n\nEtzel, F. T. (2023). One Step Closer Towards Responsible Research Assessment in Psychology: Evaluation and Testing of a New Tool in Practice. https://doi.org/10.31234/osf.io/3uf7w\n\n\n\n\n\n\n\nKey findings\n\n\n\n63 papers nominated by 21 participating researchers were rated by external raters (i.e., not the authors themselves) with the RESQUE-Pubs scheme (version 0.1). Inter-rater reliability, associations between the new and traditional indicators, and feedback from the participants on the new tool were examined. Inter-rater reliability for the three raters varied between the different items of the scheme. Besides a negative association between the new indicators and the uncorrected h-index, no other significant associations were found. The feedback from participants revealed the importance of transparency concerning the scheme.\n\n\n\nAnna Seyffert (2023)\nChristoph Heller & Jakob Fink-Lamotte (in prep.) are testing the scheme in the field of clinical psychology."
  },
  {
    "objectID": "get_profile.html",
    "href": "get_profile.html",
    "title": "üìä Get your RESQUE profile",
    "section": "",
    "text": "Warning\n\n\n\nBoth the app for entering the data and the profile are in beta stage and not finalized yet. Things might change substantially in the near future. If you want to use the RESQUE framework in practice please contact us.\n\n\nYou can enter the data for up to 10 research contributions (publications, data set, or research software) in the RESQUE Collector app.\n\nThe visualization of the results will be made available as an app in summer 2024; here‚Äôs a preview of some possible visualizations:"
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "Einstein Foundation Award\n\n\n\n\n\n\n\n\n\n\n\n2024-03-21\n\n\n\n\n\n\n\n\n\n\n\n\nNew indicators for theory-guided research developed\n\n\n\n\n\n\n\n\n\n\n\n2024-02-26\n\n\n\n\n\n\n\n\n\n\n\n\nRESQUE website is live!\n\n\n\n\n\n\n\n\n\n\n\n2023-12-12\n\n\n\n\n\n\n\n\n\n\n\n\nPreprint published by Franka Etzel on an evaluation study\n\n\n\n\n\n\n\n\n\n\n\n2023-09-04\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news/2023-12-12-website.html",
    "href": "news/2023-12-12-website.html",
    "title": "RESQUE website is live!",
    "section": "",
    "text": "We launched the RESQUE website. All material will be collected here, including news and information about case studies, evaluation projects, new indicator packs, etc."
  },
  {
    "objectID": "news/2024-03-21-Einstein_Foundation_Award.html",
    "href": "news/2024-03-21-Einstein_Foundation_Award.html",
    "title": "Einstein Foundation Award",
    "section": "",
    "text": "Anne G√§rtner received the Einstein Foundation Early Career Award 2023 for the project on Responsible Research Assessment. The project is based on RESQUE and aims to further develop and evaluate the criteria.\nThe video of the award ceremony can be seen here.\nWatch the project presentation here.\n\n\n\nEinstein Foundation Award\n\n\n\n\n\nAward Ceremony at Bode Museum, Berlin"
  },
  {
    "objectID": "publications/Commentaries.html",
    "href": "publications/Commentaries.html",
    "title": "Commentaries by the scientific community",
    "section": "",
    "text": "You can find 15 comments to our target papers 1 and 2 published in Meta-Psychology:\n\nBrown, G. (2024). A broader view of research contributions: Necessary adjustments to DORA for hiring and promotion in psychology. Meta-Psychology, 2024 (8), MP.2022.3652. https://doi.org/10.15626/MP.2024\nSandoval-Lentisco, A. (2022). Commentary: Responsible Research Assessment: Implementing DORA for hiring and promotion in psychology. Meta-Psychology, 2024 (8), MP.2022.3655. https://doi.org/10.15626/MP.2022.3655\nKarhulahti, V. (2023). Interdisciplinary value. Meta-Psychology, 2024 (8), MP.2023.3679. https://doi.org/10.15626/MP.2023.3679\nWitte, E. H. (2023). Comment on: Responsible Research Assessment I and Responsible Research Assessment II. Meta-Psychology, 2024 (8), MP.2023.3685. https://doi.org/10.15626/MP.2023.3685\nStengelin, R., Bohn, M., Sanchez-Amaro, A., Haun, D., Thiele, M., Allritz, M., ‚Ä¶ Schuhmacher, N. (2023). Responsible Research is also concerned with generalizability: Recognizing efforts to reflect upon and increase generalizability in hiring and promotion decisions in psychology. Meta-Psychology, 2024 (8), MP.2023.3695. https://doi.org/10.15626/MP.2023.3695\nBrandmaier, A. M., Ernst, M. S., & Peikert, A. (2023). Assessing rigor and impact of research software for hiring and promotion in psychology: A comment on G√§rtner et al.¬†(2022). **Meta-Psychology, 2024 (8), MP.2023.3715. https://doi.org/10.15626/MP.2023.3715\nFrischkorn, G. T. (2023). Responsible Research Assessment requires structural more than procedural reforms. Meta-Psychology, 2024 (8), MP.2023.3734. https://doi.org/10.15626/MP.2023.3734\nDames, H., Musfeld, P., Popov, V., Oberauer, K., & Frischkorn, G. T. (2023). Responsible Research Assessment Should Prioritize Theory Development and Testing Over Ticking Open Science Boxes. Meta-Psychology, 2024 (8), MP.2023.3735. https://doi.org/10.15626/MP.2023.3735\nSyed, M. (2023). Valuing Preprints Must be Part of Responsible Research Assessment. Meta-Psychology, 2024 (8), MP.2023.3758. https://doi.org/10.15626/MP.2023.3758\nHansen, M., Beitner, J., Horz, H., & Schultze, M. (2023). Indicators for teaching assessment. Meta-Psychology, 2024 (8), MP.2023.3763. https://doi.org/10.15626/MP.2023.3763\nHostler, T. (2023). Research assessment using a narrow definition of ‚Äúresearch quality‚Äù is an act of gatekeeping: A comment on G√§rtner et al.¬†(2022). **Meta-Psychology, 2024 (8), MP.2023.3764. https://doi.org/10.15626/MP.2023.3764\nAuger, V., & Claes, N. (2023). Comment on ‚ÄúResponsible Research Assessment: Implementing DORA for hiring and promotion in psychology‚Äù. Meta-Psychology, 2024 (8), MP.2023.3779. https://doi.org/10.15626/MP.2023.3779\nFink-Lamotte, J., Hilbert, K., Bentz, D., Blackwell, S. E., Boehnke, J. R., Burghardt, J., ‚Ä¶ Niemeyer, H. (2023). Response to responsible research assessment I and II from the perspective of the DGPs working group on open science in clinical psychology. Meta-Psychology, 2024 (8), MP.2023.3794. https://doi.org/10.15626/MP.2023.3794\nBrandt, H., Henninger, M., Ulitzsch, E., Kleinke, K., & Sch√§fer, T. (2023). Responsible research assessment in the area of methodological or quantitative research: A comment on G√§rtner et al.¬†(2022). **Meta-Psychology, 2024 (8), MP.2023.3796. https://doi.org/10.15626/MP.2023.3796\nUlpts, S. (2023). Responsible assessment of what research? Beware of epistemic diversity! Meta-Psychology, 2024 (8), MP.2023.3797. https://doi.org/10.15626/MP.2023.3797\n\nFurthermore, there are 6 additional commentaries (in German) published in the Psychologische Rundschau:\n\nLange, J., Degner, J., Gleibs, I. H., & Jonas, E. (2023). Fachgruppe Sozialpsychologie: Faires und valides Shortlisting in Phase 1. Psychologische Rundschau, 74(3), 187‚Äì190. https://doi.org/10.1026/0033-3042/a000641\nNiessen, C., Melchers, K. G., Ohly, S., Fay, D., Handke, L., & Kern, U. M. (2023). Fachgruppe Arbeits-, Organisations- und Wirtschaftspsychologie: Ein Pl√§doyer f√ºr breit gew√§hlte und anforderungsbezogene Leistungsindikatoren. Psychologische Rundschau, 74(3), 180‚Äì182. https://doi.org/10.1026/0033-3042/a000637\nOrtner, T., Kretzschmar, A., Rauthmann, J. F., & Tibubos, A. N. (2023). Fachgruppe Differentielle Psychologie, Pers√∂nlichkeitspsychologie und psychologische Diagnostik: Berufungsverfahren unter einer diagnostischen Perspektive fundiert durchf√ºhren. Psychologische Rundschau, 74(3), 182‚Äì184. https://doi.org/10.1026/0033-3042/a000638\nSchwartz, B., Szota, K., Schmitz, J., Lueken, U., & Lincoln, T. (2023). Fachgruppe Klinische Psychologie und Psychotherapie: Mehr Differenzierung nach Fachgebieten. Psychologische Rundschau, 74(3), 184‚Äì185. https://doi.org/10.1026/0033-3042/a000639\nSparfeldt, J. R., Sp√∂rer, N., Greiff, S., & Schneider, R. (2023). Fachgruppe P√§dagogische Psychologie: Ein Pl√§doyer f√ºr valide‚Äç(re) Bewertungen der wissenschaftlichen Leistungen in Berufungsverfahren. Psychologische Rundschau, 74(3), 185‚Äì187. https://doi.org/10.1026/0033-3042/a000640\nStroebe, W., & Strack, F. (2023). Kommentare zu G√§rtner, A. et al.¬†(2023). Empfehlungen zur Bewertung wissenschaftlicher Leistungen bei Berufungsverfahren in der Psychologie: Zweierlei Ma√ü? Warum manche Psychologen den Gebrauch von quantitativen Indikatoren der Forschungsqualit√§t ablehnen. Psychologische Rundschau, 74(3), 175‚Äì179. https://doi.org/10.1026/0033-3042/a000631",
    "crumbs": [
      "üìî Publications",
      "Commentaries by the scientific community"
    ]
  },
  {
    "objectID": "rating_schemes.html",
    "href": "rating_schemes.html",
    "title": "üìë The Rating Schemes",
    "section": "",
    "text": "TODO: Show all indicators for the three ratings schemes\nThe rating sheets are versioned. Indicators from the core set start with the prefix ‚ÄòP‚Äô (Publications), ‚ÄòD‚Äô (Data) or ‚ÄòS‚Äô (Software)."
  },
  {
    "objectID": "technical_docs.html",
    "href": "technical_docs.html",
    "title": "‚éî Technical documentation",
    "section": "",
    "text": "(To be done)\nThe json files can be imported in R with the RESQUER package. The package preprocesses the data and enriches it with ‚Ä¶\n\ncitation metrics from OpenAlex\nimpact metrics from BIP!\nthe TOP factor for the journals the author is publishing in\n\nFurthermore, the package provides an interactive dashboard that allows to compare multiple candidates:"
  }
]